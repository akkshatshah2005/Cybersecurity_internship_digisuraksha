import unicodedata
import difflib

# List of real domains to compare
whitelist = ['google.com', 'facebook.com', 'apple.com', 'amazon.com', 'microsoft.com']

# Basic homoglyph map
homoglyphs = {
    'Ğ°': 'a', 'Ğµ': 'e', 'Ñ–': 'i', 'Ğ¾': 'o', 'Ñ€': 'p',
    'Ñ•': 's', 'É¡': 'g', 'Ó': 'l', 'Ò»': 'h', 'Ê': 'y'
}

# Fixes Unicode & replaces suspicious characters
def clean(domain):
    norm = unicodedata.normalize('NFKC', domain)
    fixed = ''.join(homoglyphs.get(c, c) for c in norm)
    return norm, fixed

# Compares with known domains
def check(domain):
    norm, clean_domain = clean(domain)
    if any(ord(c) > 127 for c in norm):
        print(f"\nâš ï¸ Suspicious Unicode in: {domain}")
        print(f"ğŸ”¹ Normalized: {norm}")
        print(f"ğŸ”¹ Replaced:   {clean_domain}")
        for legit in whitelist:
            sim = difflib.SequenceMatcher(None, clean_domain, legit).ratio()
            if sim > 0.8:
                print(f"â— Looks like: {legit} (Similarity: {round(sim, 2)})")
    else:
        print("âœ… Domain looks clean.")

# Run
if __name__ == "__main__":
    domain = input("Enter domain to check: ")
    check(domain)
